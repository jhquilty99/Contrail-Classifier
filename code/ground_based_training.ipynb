{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Contrail Classifier\n",
    "The goal of this project is to train a machine learning model that can accurately classify images of the sky as containing contrails.\n",
    "To build the model, we have obtained cloud data from four sources:\n",
    "1. [Cirrus Cumulus Stratus Nimbus (CCSN) Database](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/CADDPD), this \n",
    "2. [Singapore Data Swimcat](https://ieeexplore.ieee.org/abstract/document/7350833)\n",
    "3. [CLASA](https://github.com/CLASA/Contrail-Machine-Vision), [Official Website](https://clasa.github.io/) a proposed solution to the NASA Clouds vs Contrails challenge.\n",
    "4. [Google Cloud Project](https://arxiv.org/abs/2304.02122)\n",
    "\n",
    "Potential applications are noted below:\n",
    "\n",
    "Potential Applications\n",
    "* Climate Studies: Contrails can have a significant impact on the Earth's atmosphere and climate. They can reflect sunlight back into space, contributing to global cooling, but they can also trap heat within the Earth's atmosphere, contributing to global warming. Therefore, a machine learning model trained to detect and monitor contrails could provide important data for climate researchers.\n",
    "\n",
    "* Air Traffic Control: A model trained to identify contrails could be useful in tracking aircraft routes and densities, particularly in areas with less developed radar infrastructure.\n",
    "\n",
    "* Aerospace and Defense: This model could be used for aerospace and defense purposes. For instance, detecting contrails could help in tracking and identifying stealth, unauthorized, or unrecognized flights, which can be important in maintaining airspace security."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Script\n",
    "Preprocessing is a crucial step in the machine learning pipeline because the quality and quantity of the data that you feed into your model will directly determine how well it can learn. Here are some reasons how we could preprocess image data:\n",
    "* Labeling: These images are not all labeled, and images from different datasets. The purpose of labeling is to homogenize the data so that each image is labeled in the same manner.\n",
    "\n",
    "* Image Resizing: In real-world scenarios, images can come in different sizes and aspect ratios. However, many computer vision models (like Convolutional Neural Networks) require images to be of a uniform size. Therefore, images often need to be resized to fit the requirements of the model.\n",
    "\n",
    "* Normalization: Image pixel intensities can range from 0 to 255. Normalizing these pixel intensities to a smaller range, often between 0 and 1 or -1 and 1, can help the model learn more effectively. This is because smaller, centered values are easier for the model's weight initialization and optimization process. Scaling the pixel values of the images to a small range like 0-1 or -1 to 1 can help the model converge faster during training. The 'Rescaling' layer in TensorFlow can be used for this purpose.\n",
    "\n",
    "* Data Augmentation: Image datasets can be augmented by applying random transformations like rotation, scaling, translation, flip etc. This can help increase the amount of training data and make the model more robust to variations in the input data that it hasn't seen before. This can help the model generalize better to new data. TensorFlow provides tools for data augmentation in the 'tf.keras.layers.experimental.preprocessing' module.\n",
    "\n",
    "* Dealing with Color Channels: Some models might require grayscale images, while others might require color images. Depending on the model, you might need to convert images from color to grayscale, or vice versa. Depending on your data, you might find that transforming the color space of your images (from RGB to HSV, Lab, YUV, etc.) could improve your model's ability to detect features.\n",
    "\n",
    "* Feature Extraction: In some cases, it might be beneficial to manually extract features from the images, such as edges, corners, and other local features. These can be used as inputs to the machine learning model. For contrails detection, specific filters that are sensitive to the features of contrails could be used. This might require some research and experimentation.\n",
    "\n",
    "* Dimensionality Reduction: Images are high-dimensional data, and it may be beneficial to reduce their dimensionality. This can be done through techniques like Principal Component Analysis (PCA) or autoencoders, which can make the model more efficient without losing too much information.\n",
    "\n",
    "* Balancing Classes: If the numbers of contrail and no-contrail images are not roughly equal, the model might become biased towards the more common class. Solutions include oversampling the minority class, undersampling the majority class, or using a combination of both.\n",
    "\n",
    "These preprocessing steps help to make the image data more suitable for computer vision models and can lead to better performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data and Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_loader(image_dir, dictionary):\n",
    "    # List to hold all image data\n",
    "    images = list()\n",
    "    # List to hold image classifications (1,0)\n",
    "    classes = list()\n",
    "    # List to hold folders\n",
    "    folders = list()\n",
    "    # Specify the common size to resize all images\n",
    "    common_size = (400, 400)\n",
    "    # Iterate over each image in the directory\n",
    "    for folder in os.listdir(image_dir):\n",
    "        # Only open files with the specified filetype extension (e.g., \".png\" or \".jpg\")\n",
    "        for filename in os.listdir(os.path.join(image_dir, folder)):\n",
    "            if filename.endswith('.jpg'):\n",
    "                # Open each image file\n",
    "                img_path = os.path.join(image_dir, folder, filename)\n",
    "                img = Image.open(img_path)\n",
    "                # Resize image to the common size\n",
    "                img = ImageOps.fit(img, common_size, Image.Resampling.LANCZOS)\n",
    "                # Append the image data to your list\n",
    "                images.append(img)\n",
    "                classes.append(dictionary[folder])\n",
    "                folders.append(image_dir)\n",
    "    # Now the 'images' list contains all the images in the image_dir as PIL Image objects, with the labels in the 'classes' list\n",
    "    return np.array([np.array(image) for image in images]), np.array(classes), np.array(folders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_class_proportion(classes):\n",
    "    print(f'This array contains {round(np.mean(100*classes),2)}% contrails')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"../data/Roboflow\"\n",
    "robo_dictionary = {\n",
    "    'Contrail':1,\n",
    "    'No_contrail':0\n",
    "}\n",
    "images_robo, classes_robo, folder_robo = image_loader(image_dir, robo_dictionary)\n",
    "print(f'From Roboflow we extract {len(images_robo)} images from {len(np.unique(classes_robo))} distinct classes')\n",
    "print_class_proportion(classes_robo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"../data/CCSN_v2\"\n",
    "ccsn_dictionary = {\n",
    "    'Ct':1,\n",
    "    'Ac':0, 'Sc':0, 'Ns':0, 'Cu':0, 'Ci':0, 'Cc':0, 'Cb':0, 'As':0, 'Cs':0, 'St':0\n",
    "}\n",
    "images_ccsn, classes_ccsn, folder_ccsn = image_loader(image_dir, ccsn_dictionary)\n",
    "print(f'From CCSN we extract {len(images_ccsn)} images from {len(np.unique(classes_ccsn))} distinct classes')\n",
    "print_class_proportion(classes_ccsn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"../data/CLASA\"\n",
    "clasa_dictionary = {\n",
    "    'Contrail':1,\n",
    "    'Cirrus':0\n",
    "}\n",
    "images_clasa, classes_clasa, folder_clasa = image_loader(image_dir, clasa_dictionary)\n",
    "print(f'From CLASA we extract {len(images_clasa)} images from {len(np.unique(classes_clasa))} distinct classes')\n",
    "print_class_proportion(classes_clasa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"../data/Singapore Data Swimcat\"\n",
    "singapore_dictionary = {\n",
    "    'A-sky':0,\n",
    "    'B-pattern':0,\n",
    "    'C-thick-dark':0,\n",
    "    'D-thick-white':0,\n",
    "    'E-veil':0\n",
    "}\n",
    "images_singapore, classes_singapore, folder_singapore = image_loader(image_dir, singapore_dictionary)\n",
    "print(f'From Singapore we extract {len(images_singapore)} images from {len(np.unique(classes_singapore))} distinct classes')\n",
    "print_class_proportion(classes_singapore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all the folders into two lists: one containing images, and the other has the labels\n",
    "images_all = np.concatenate([images_robo, images_ccsn, images_clasa, images_singapore])\n",
    "classes_all = np.concatenate([classes_robo, classes_ccsn, classes_clasa, classes_singapore])\n",
    "folders_all = np.concatenate([folder_robo, folder_ccsn, folder_clasa, folder_singapore])\n",
    "print(images_all[0:5])\n",
    "print(classes_all[0:5])\n",
    "print(f'In total we have extracted {len(images_all)} images from {len(np.unique(classes_all))} distinct classes')\n",
    "# Do some feature analysis to see the distribution of response variable\n",
    "print_class_proportion(classes_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some feature analysis to see the distribution of input iamges\n",
    "def image_dimension(images):\n",
    "    # Get dimensions of images\n",
    "    dimensions = [img.shape for img in images]\n",
    "\n",
    "    # Split dimensions into two lists: width and height\n",
    "    widths = [dim[1] for dim in dimensions]\n",
    "    heights = [dim[0] for dim in dimensions]\n",
    "\n",
    "\n",
    "    # Create subplots: 2 rows, 1 column\n",
    "    fig = make_subplots(rows=3, cols=1)\n",
    "\n",
    "    # Add histogram for widths to the first subplot\n",
    "    fig.add_trace(\n",
    "        go.Histogram(x=widths, name='widths', opacity=0.75),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    # Add histogram for heights to the second subplot\n",
    "    fig.add_trace(\n",
    "        go.Histogram(x=heights, name='heights', opacity=0.75),\n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "    # Add histogram for heights to the second subplot\n",
    "    fig.add_trace(\n",
    "        go.Histogram(x=np.array(widths)/np.array(heights), name='aspect_ratio', opacity=0.75),\n",
    "        row=3, col=1\n",
    "    )\n",
    "\n",
    "    # Update xaxis titles\n",
    "    fig.update_xaxes(title_text='Widths', row=1, col=1)\n",
    "    fig.update_xaxes(title_text='Heights', row=2, col=1)\n",
    "    fig.update_xaxes(title_text='Aspect Ratio', row=3, col=1)\n",
    "\n",
    "    # Update yaxis titles\n",
    "    fig.update_yaxes(title_text='Count', row=1, col=1)\n",
    "    fig.update_yaxes(title_text='Count', row=2, col=1)\n",
    "    fig.update_yaxes(title_text='Count', row=3, col=1)\n",
    "\n",
    "    # Update layout to show subplots\n",
    "    fig.update_layout(\n",
    "        title_text='Distribution of Image Widths and Heights', # title of plot\n",
    "        height=600, # height of plot in pixels\n",
    "        width=900, # width of plot in pixels\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dimension(images_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most common pixel size so that we can make squares out of that size\n",
    "# Get dimensions of images\n",
    "dimensions = [img.shape for img in images_all]\n",
    "\n",
    "# Split dimensions into two lists: width and height\n",
    "# For numpy array dimensions, the first dimension is height and the second one is width\n",
    "heights = [dim[0] for dim in dimensions]\n",
    "widths = [dim[1] for dim in dimensions]\n",
    "\n",
    "most_common_width = Counter(widths).most_common(1)[0][0]\n",
    "most_common_height = Counter(heights).most_common(1)[0][0]\n",
    "print(f'From all images, the most_common width is {most_common_width} px and the most common height is {most_common_height} px')\n",
    "print(f'From all images, the smallest width is {np.min(widths)} px and the maximum width is {np.max(widths)} px')\n",
    "print(f'From all images, the smallest height is {np.min(heights)} px and the maximum width is {np.max(heights)} px')\n",
    "\n",
    "# Get the index of the biggest image in the dimensions list\n",
    "def biggest_image(dimensions):\n",
    "    for i in range(0, len(dimensions)): \n",
    "        # use dim[1] to check the width, because dim[0] is the height for numpy arrays\n",
    "        if dimensions[i][1] == np.max(widths):\n",
    "            return i\n",
    "\n",
    "print(f'From all images biggest image is {biggest_image(dimensions)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***COMMENTED OUT Does not work with PIL library, therefore we resized images above***\n",
    "# Make the images square and do other transformations\n",
    "\n",
    "#pixels = 400\n",
    "#images_all_squared = []\n",
    "#classes_all_squared = []\n",
    "#i = 0\n",
    "# this will not work because Pil objects use .shhape and not .size\n",
    "#for img in images_all:\n",
    "    #width, height = img.size\n",
    "    #if width < pixels or height < pixels:\n",
    "        # Calculate padding\n",
    "       # width_padding = pixels - width\n",
    "      #  height_padding = pixels - height\n",
    "        # Apply padding with a grey background\n",
    "     #   images_all_squared.append(ImageOps.pad(img, (pixels,pixels), color=125))\n",
    "    #elif width > 400 or height > 400:\n",
    "        # Try both shrinking the image and cropping the image to create syntetic samples\n",
    "        # Image.LANCZOS applies a high-quality downsampling filter\n",
    "       # images_all_squared.append(img.resize((pixels, pixels), Image.LANCZOS))\n",
    "        # Returns a resized and cropped version of the image, cropped to the requested aspect ratio and size.\n",
    "      #  images_all_squared.append(ImageOps.fit(img, (pixels, pixels)))\n",
    "        # Because we are expanding the dataset, make sure to add the extra class labels\n",
    "     #   classes_all_squared.append(classes_all[i])\n",
    "    #else:\n",
    "   #     images_all_squared.append(img)\n",
    "  #  classes_all_squared.append(classes_all[i])\n",
    " #   i += 1\n",
    "#\n",
    "#print(f'In total we have turned {len(images_all)} raw images into {len(images_all_squared)} square images with {pixels} px sides')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_dimension(images_all_squared)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# This one uses the resized NP data\n",
    "# Assume X is your array of features and y are the labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(images_all, classes_all, test_size=0.2, random_state=42)\n",
    "print(f'X_train is {len(X_train)} images long')\n",
    "print(f'X_test is {len(X_test)} images long')\n",
    "print(f'y_train is {len(y_train)} labels long')\n",
    "print(f'y_test is {len(y_test)} labels long')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***Commented out reasons outlined above***\n",
    "\n",
    "# Assume X is your array of features and y are the labels\n",
    "#X_train, X_test, y_train, y_test = train_test_split(images_all_squared, classes_all_squared, test_size=0.2, random_state=42)\n",
    "#print(f'X_train is {len(X_train)} images long')\n",
    "#print(f'X_test is {len(X_test)} images long')\n",
    "#print(f'y_train is {len(y_train)} labels long')\n",
    "#print(f'y_test is {len(y_test)} labels long')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with Color Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_datagen = ImageDataGenerator(\n",
    "#     rescale = 1/255,\n",
    "#     shear_range = 0.2,\n",
    "#     zoom_range = 0.2,\n",
    "#     horizontal_flip = True\n",
    "#     )\n",
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "#random_datagen.fit(np.array(X_train))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import ResNet50\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pre-built ResNet50 model\n",
    "base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "\n",
    "# Add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "# Add a logistic layer for binary classification\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# This is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# First: train only the top layers (which were randomly initialized)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Model in Azure Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.identity import InteractiveBrowserCredential\n",
    "\n",
    "subscription_id = '81ccb9cf-adc5-4eac-b781-5b1fc76926f7'\n",
    "resource_group = 'ContrailResourceGroup'\n",
    "workspace = 'Contrail-Classifier'\n",
    "\n",
    "tenant_id = \"85b77843-1ccd-4a9b-9b12-baa93c8b4d37\"\n",
    "\n",
    "# Connect to the workspace\n",
    "ml_client = MLClient(InteractiveBrowserCredential(tenant_id=tenant_id), subscription_id, resource_group, workspace)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a compute resource for training\n",
    "\n",
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "# Specify aml compute name\n",
    "cpu_compute_target = \"cpu-cluster\"\n",
    "\n",
    "try:\n",
    "    ml_client.compute.get(cpu_compute_target)\n",
    "except Exception:\n",
    "    print(\"Creating a new cpu compute target...\")\n",
    "    compute = AmlCompute(\n",
    "        name=cpu_compute_target, size=\"STANDARD_D2s_v3\", min_instances=0, max_instances=4\n",
    "    )\n",
    "    ml_client.compute.begin_create_or_update(compute).result()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sebas\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n",
      "'enabled' is deprecated. Please use the azureml.core.runconfig.DockerConfiguration object with the 'use_docker' param instead.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace, Environment, Experiment, ScriptRunConfig\n",
    "\n",
    "# Connect to the workspace\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "# Creates a new Azure Machine Learning Environment\n",
    "myenv = Environment(\"myenv\")\n",
    "\n",
    "# Enable Docker and add necessary packages\n",
    "myenv.docker.enabled = True\n",
    "myenv.python.conda_dependencies.add_pip_package(\"keras\")\n",
    "myenv.python.conda_dependencies.add_pip_package(\"numpy\")\n",
    "myenv.python.conda_dependencies.add_pip_package(\"tensorflow\")\n",
    "myenv.python.conda_dependencies.add_pip_package(\"scikit-learn\")\n",
    "myenv.python.conda_dependencies.add_pip_package(\"azure-ai-ml\")\n",
    "myenv.python.conda_dependencies.add_pip_package(\"Pillow\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ScriptRunConfig\n",
    "\n",
    "source_directory = 'C:/Users/sebas/OneDrive/Documents/Contrail/Contrail-Classifier/code'  \n",
    "script = 'Ground_Based_Training_script.py'\n",
    "compute_target = \"cpu-cluster\"\n",
    "\n",
    "# Create the ScriptRunConfig object\n",
    "src = ScriptRunConfig(source_directory=source_directory, script=script, compute_target=compute_target, environment=myenv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: contrail_classifier_1690952204_c78a77a3\n",
      "Web View: https://ml.azure.com/runs/contrail_classifier_1690952204_c78a77a3?wsid=/subscriptions/81ccb9cf-adc5-4eac-b781-5b1fc76926f7/resourcegroups/ContrailResourceGroup/workspaces/Contrail-Classifier&tid=85b77843-1ccd-4a9b-9b12-baa93c8b4d37\n",
      "\n",
      "Streaming azureml-logs/20_image_build_log.txt\n",
      "=============================================\n",
      "\n",
      "2023/08/02 04:56:52 Downloading source code...\n",
      "2023/08/02 04:56:53 Finished downloading source code\n",
      "2023/08/02 04:56:54 Creating Docker network: acb_default_network, driver: 'bridge'\n",
      "2023/08/02 04:56:54 Successfully set up Docker network: acb_default_network\n",
      "2023/08/02 04:56:54 Setting up Docker configuration...\n",
      "2023/08/02 04:56:55 Successfully set up Docker configuration\n",
      "2023/08/02 04:56:55 Logging in to registry: 19fdcc1f9a94406985698a8d8e694586.azurecr.io\n",
      "2023/08/02 04:56:55 Successfully logged into 19fdcc1f9a94406985698a8d8e694586.azurecr.io\n",
      "2023/08/02 04:56:56 Volume source scriptsFromEms successfully created\n",
      "2023/08/02 04:56:56 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2023/08/02 04:56:56 Scanning for dependencies...\n",
      "2023/08/02 04:56:57 Successfully scanned dependencies\n",
      "2023/08/02 04:56:57 Launching container with name: acb_step_0\n",
      "Sending build context to Docker daemon  77.31kB\n",
      "\n",
      "Step 1/21 : FROM mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20230620.v1@sha256:d87e60a40761fd1bb9efa97d94a9ec52b62a9e7081fd2acd5c7d94ba2852d60a\n",
      "mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20230620.v1@sha256:d87e60a40761fd1bb9efa97d94a9ec52b62a9e7081fd2acd5c7d94ba2852d60a: Pulling from azureml/openmpi4.1.0-ubuntu20.04\n",
      "f0412dfb1aae: Already exists\n",
      "2335b08db55d: Pulling fs layer\n",
      "4c6821e3fe1d: Pulling fs layer\n",
      "5932a200f0bf: Pulling fs layer\n",
      "33c1fe43af46: Pulling fs layer\n",
      "e97cedf7a795: Pulling fs layer\n",
      "b2f0588cc721: Pulling fs layer\n",
      "fcf20f972570: Pulling fs layer\n",
      "b727183c795c: Pulling fs layer\n",
      "87ffdc8de2d2: Pulling fs layer\n",
      "33c1fe43af46: Waiting\n",
      "e97cedf7a795: Waiting\n",
      "b2f0588cc721: Waiting\n",
      "fcf20f972570: Waiting\n",
      "87ffdc8de2d2: Waiting\n",
      "4c6821e3fe1d: Verifying Checksum\n",
      "4c6821e3fe1d: Download complete\n",
      "5932a200f0bf: Verifying Checksum\n",
      "5932a200f0bf: Download complete\n",
      "33c1fe43af46: Verifying Checksum\n",
      "33c1fe43af46: Download complete\n",
      "b2f0588cc721: Verifying Checksum\n",
      "b2f0588cc721: Download complete\n",
      "e97cedf7a795: Verifying Checksum\n",
      "e97cedf7a795: Download complete\n",
      "fcf20f972570: Verifying Checksum\n",
      "fcf20f972570: Download complete\n",
      "b727183c795c: Verifying Checksum\n",
      "b727183c795c: Download complete\n",
      "87ffdc8de2d2: Verifying Checksum\n",
      "87ffdc8de2d2: Download complete\n",
      "2335b08db55d: Verifying Checksum\n",
      "2335b08db55d: Download complete\n",
      "2335b08db55d: Pull complete\n",
      "4c6821e3fe1d: Pull complete\n",
      "5932a200f0bf: Pull complete\n",
      "33c1fe43af46: Pull complete\n",
      "e97cedf7a795: Pull complete\n",
      "b2f0588cc721: Pull complete\n",
      "fcf20f972570: Pull complete\n",
      "b727183c795c: Pull complete\n",
      "87ffdc8de2d2: Pull complete\n",
      "Digest: sha256:d87e60a40761fd1bb9efa97d94a9ec52b62a9e7081fd2acd5c7d94ba2852d60a\n",
      "Status: Downloaded newer image for mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20230620.v1@sha256:d87e60a40761fd1bb9efa97d94a9ec52b62a9e7081fd2acd5c7d94ba2852d60a\n",
      " ---> 59f39c44073e\n",
      "Step 2/21 : USER root\n",
      " ---> Running in 344833db6e59\n",
      "Removing intermediate container 344833db6e59\n",
      " ---> dc756fb64a5b\n",
      "Step 3/21 : RUN mkdir -p $HOME/.cache\n",
      " ---> Running in c97db8d58f7d\n",
      "Removing intermediate container c97db8d58f7d\n",
      " ---> 1227abf9ede2\n",
      "Step 4/21 : WORKDIR /\n",
      " ---> Running in ca639bfbb9e9\n",
      "Removing intermediate container ca639bfbb9e9\n",
      " ---> 4764f580b37e\n",
      "Step 5/21 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
      " ---> 6b94c5e2ec7e\n",
      "Step 6/21 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n",
      " ---> Running in f9e4c0a5e6c6\n",
      "Removing intermediate container f9e4c0a5e6c6\n",
      " ---> 51948bcc07d2\n",
      "Step 7/21 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n",
      " ---> dfa53d1bab5c\n",
      "Step 8/21 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_25db23ddda1880ffc26d032761a7488f -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n",
      " ---> Running in cec2a905dbaa\n",
      "Retrieving notices: ...working... done\n",
      "Warning: you have pip-installed dependencies in your environment file, but you do not list pip itself as one of your conda dependencies.  Conda may not use the correct pip to install your packages, and they may end up in the wrong place.  Please add an explicit pip dependency.  I'm adding one for you, but still nagging you.\n",
      "Collecting package metadata (repodata.json): ...working... \n",
      "done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "wheel-0.37.1         | 31 KB     |            |   0% \u001b[91m\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.5.0\n",
      "  latest version: 23.7.2\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c conda-forge conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.7.2\n",
      "\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "zlib-1.2.13          | 125 KB    |            |   0% \u001b[A\n",
      "\n",
      "\n",
      "python-3.8.13        | 24.3 MB   |            |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pip-22.3.1           | 2.7 MB    |            |   0% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_openmp_mutex-5.1    | 20 KB     |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2023 | 127 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libstdcxx-ng-11.2.0  | 6.1 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libgomp-11.2.0       | 560 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sqlite-3.40.1        | 1.6 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ld_impl_linux-64-2.3 | 732 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "readline-8.2         | 457 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libgcc-ng-11.2.0     | 8.5 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tk-8.6.12            | 3.3 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "certifi-2022.12.7    | 152 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libffi-3.3           | 54 KB     |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ncurses-6.4          | 1.1 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_libgcc_mutex-0.1    | 3 KB      |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "setuptools-65.6.3    | 1.4 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "xz-5.2.10            | 449 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pip-22.3.1           | 2.7 MB    | ##6        |  26% \u001b[A\u001b[A\u001b[A\n",
      "wheel-0.37.1         | 31 KB     | #####1     |  52% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libstdcxx-ng-11.2.0  | 6.1 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2023 | 127 KB    | #2         |  13% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libgomp-11.2.0       | 560 KB    | 2          |   3% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "zlib-1.2.13          | 125 KB    | #2         |  13% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sqlite-3.40.1        | 1.6 MB    | 1          |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libstdcxx-ng-11.2.0  | 6.1 MB    | #8         |  19% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "wheel-0.37.1         | 31 KB     | ########## | 100% \n",
      "wheel-0.37.1         | 31 KB     | ########## | 100% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ld_impl_linux-64-2.3 | 732 KB    | 2          |   2% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "python-3.8.13        | 24.3 MB   |            |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "readline-8.2         | 457 KB    | 3          |   4% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sqlite-3.40.1        | 1.6 MB    | ########2  |  83% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libgcc-ng-11.2.0     | 8.5 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libstdcxx-ng-11.2.0  | 6.1 MB    | ###3       |  34% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2023 | 127 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2023 | 127 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "python-3.8.13        | 24.3 MB   | 3          |   4% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tk-8.6.12            | 3.3 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "certifi-2022.12.7    | 152 KB    | #          |  11% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libstdcxx-ng-11.2.0  | 6.1 MB    | ####9      |  49% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libgcc-ng-11.2.0     | 8.5 MB    | #1         |  12% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libffi-3.3           | 54 KB     | ##9        |  30% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_openmp_mutex-5.1    | 20 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_openmp_mutex-5.1    | 20 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "python-3.8.13        | 24.3 MB   | #          |  10% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tk-8.6.12            | 3.3 MB    | ####1      |  41% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ncurses-6.4          | 1.1 MB    | 1          |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libgcc-ng-11.2.0     | 8.5 MB    | ##4        |  25% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libstdcxx-ng-11.2.0  | 6.1 MB    | ######5    |  65% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "python-3.8.13        | 24.3 MB   | #5         |  16% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tk-8.6.12            | 3.3 MB    | #######6   |  76% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_libgcc_mutex-0.1    | 3 KB      | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libgcc-ng-11.2.0     | 8.5 MB    | ###6       |  37% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libstdcxx-ng-11.2.0  | 6.1 MB    | ########2  |  83% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "setuptools-65.6.3    | 1.4 MB    | 1          |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "python-3.8.13        | 24.3 MB   | ##         |  21% \u001b[A\u001b[A\n",
      "\n",
      "zlib-1.2.13          | 125 KB    | ########## | 100% \u001b[A\n",
      "\n",
      "zlib-1.2.13          | 125 KB    | ########## | 100% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "xz-5.2.10            | 449 KB    | 3          |   4% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libgcc-ng-11.2.0     | 8.5 MB    | #####1     |  51% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "python-3.8.13        | 24.3 MB   | ##6        |  26% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libgcc-ng-11.2.0     | 8.5 MB    | ########1  |  81% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "python-3.8.13        | 24.3 MB   | ###4       |  35% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "python-3.8.13        | 24.3 MB   | ####5      |  45% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libgomp-11.2.0       | 560 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libgomp-11.2.0       | 560 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "python-3.8.13        | 24.3 MB   | #####9     |  59% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "python-3.8.13        | 24.3 MB   | #######2   |  73% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "python-3.8.13        | 24.3 MB   | #########  |  90% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ld_impl_linux-64-2.3 | 732 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ld_impl_linux-64-2.3 | 732 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sqlite-3.40.1        | 1.6 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "readline-8.2         | 457 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "readline-8.2         | 457 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "certifi-2022.12.7    | 152 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "certifi-2022.12.7    | 152 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libffi-3.3           | 54 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libffi-3.3           | 54 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pip-22.3.1           | 2.7 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pip-22.3.1           | 2.7 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_libgcc_mutex-0.1    | 3 KB      | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ncurses-6.4          | 1.1 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ncurses-6.4          | 1.1 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tk-8.6.12            | 3.3 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "xz-5.2.10            | 449 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "xz-5.2.10            | 449 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "setuptools-65.6.3    | 1.4 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "setuptools-65.6.3    | 1.4 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libstdcxx-ng-11.2.0  | 6.1 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libstdcxx-ng-11.2.0  | 6.1 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libgcc-ng-11.2.0     | 8.5 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libgcc-ng-11.2.0     | 8.5 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "python-3.8.13        | 24.3 MB   | ########## | 100% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                      \n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "                                                     \n",
      "\n",
      "                                                     \u001b[A\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Installing pip dependencies: ...working... \n",
      "Ran pip subprocess with arguments:\n",
      "['/azureml-envs/azureml_25db23ddda1880ffc26d032761a7488f/bin/python', '-m', 'pip', 'install', '-U', '-r', '/azureml-environment-setup/condaenv.nfmbwtn4.requirements.txt', '--exists-action=b']\n",
      "Pip subprocess output:\n",
      "Collecting azureml-defaults\n",
      "  Downloading azureml_defaults-1.52.0-py3-none-any.whl (2.0 kB)\n",
      "Collecting keras\n",
      "  Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "      1.7/1.7 MB 71.3 MB/s eta 0:00:00\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "      17.3/17.3 MB 86.0 MB/s eta 0:00:00\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.13.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.1 MB)\n",
      "      524.1/524.1 MB 6.6 MB/s eta 0:00:00\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.3.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\n",
      "      11.1/11.1 MB 108.6 MB/s eta 0:00:00\n",
      "Collecting azure-ai-ml\n",
      "  Downloading azure_ai_ml-1.9.0-py3-none-any.whl (6.9 MB)\n",
      "      6.9/6.9 MB 99.4 MB/s eta 0:00:00\n",
      "Collecting Pillow\n",
      "  Downloading Pillow-10.0.0-cp38-cp38-manylinux_2_28_x86_64.whl (3.4 MB)\n",
      "      3.4/3.4 MB 101.3 MB/s eta 0:00:00\n",
      "Collecting azureml-inference-server-http~=0.8.0\n",
      "  Downloading azureml_inference_server_http-0.8.4-py3-none-any.whl (58 kB)\n",
      "      58.4/58.4 kB 12.1 MB/s eta 0:00:00\n",
      "Collecting azureml-dataset-runtime[fuse]~=1.52.0\n",
      "  Downloading azureml_dataset_runtime-1.52.0-py3-none-any.whl (2.3 kB)\n",
      "Collecting azureml-core~=1.52.0\n",
      "  Downloading azureml_core-1.52.0-py3-none-any.whl (3.3 MB)\n",
      "      3.3/3.3 MB 80.0 MB/s eta 0:00:00\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.24.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "      17.3/17.3 MB 74.6 MB/s eta 0:00:00\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=23.1.21\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting h5py>=2.9.0\n",
      "  Downloading h5py-3.9.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "      4.8/4.8 MB 86.3 MB/s eta 0:00:00\n",
      "Collecting typing-extensions<4.6.0,>=3.6.6\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-4.23.4-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
      "      304.5/304.5 kB 56.4 MB/s eta 0:00:00\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "      57.5/57.5 kB 12.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: setuptools in /azureml-envs/azureml_25db23ddda1880ffc26d032761a7488f/lib/python3.8/site-packages (from tensorflow->-r /azureml-environment-setup/condaenv.nfmbwtn4.requirements.txt (line 4)) (65.6.3)\n",
      "Collecting tensorboard<2.14,>=2.13\n",
      "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "      5.6/5.6 MB 93.7 MB/s eta 0:00:00\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "      65.5/65.5 kB 14.8 MB/s eta 0:00:00\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.6-py2.py3-none-manylinux2010_x86_64.whl (22.9 MB)\n",
      "      22.9/22.9 MB 88.2 MB/s eta 0:00:00\n",
      "Collecting packaging\n",
      "  Downloading packaging-23.1-py3-none-any.whl (48 kB)\n",
      "      48.9/48.9 kB 10.3 MB/s eta 0:00:00\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.15.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (81 kB)\n",
      "      81.5/81.5 kB 19.5 MB/s eta 0:00:00\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.33.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "      2.4/2.4 MB 83.1 MB/s eta 0:00:00\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting tensorflow-estimator<2.14,>=2.13.0\n",
      "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "      440.8/440.8 kB 32.4 MB/s eta 0:00:00\n",
      "Collecting six>=1.12.0\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "      126.5/126.5 kB 29.4 MB/s eta 0:00:00\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.56.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
      "      5.2/5.2 MB 62.2 MB/s eta 0:00:00\n",
      "Collecting joblib>=1.1.1\n",
      "  Downloading joblib-1.3.1-py3-none-any.whl (301 kB)\n",
      "      302.0/302.0 kB 64.4 MB/s eta 0:00:00\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Collecting scipy>=1.5.0\n",
      "  Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
      "      34.5/34.5 MB 65.2 MB/s eta 0:00:00\n",
      "Collecting isodate\n",
      "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "      41.7/41.7 kB 9.3 MB/s eta 0:00:00\n",
      "Collecting colorama<0.5.0\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Collecting azure-common<2.0.0,>=1.1\n",
      "  Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
      "Collecting azure-storage-file-datalake<13.0.0\n",
      "  Downloading azure_storage_file_datalake-12.12.0-py3-none-any.whl (247 kB)\n",
      "      247.8/247.8 kB 48.8 MB/s eta 0:00:00\n",
      "Collecting msrest>=0.6.18\n",
      "  Downloading msrest-0.7.1-py3-none-any.whl (85 kB)\n",
      "      85.4/85.4 kB 19.3 MB/s eta 0:00:00\n",
      "Collecting azure-storage-blob<13.0.0,>=12.10.0\n",
      "  Downloading azure_storage_blob-12.17.0-py3-none-any.whl (388 kB)\n",
      "      388.0/388.0 kB 62.3 MB/s eta 0:00:00\n",
      "Collecting pydash<6.0.0\n",
      "  Downloading pydash-5.1.2-py3-none-any.whl (84 kB)\n",
      "      85.0/85.0 kB 10.3 MB/s eta 0:00:00\n",
      "Collecting azure-storage-file-share<13.0.0\n",
      "  Downloading azure_storage_file_share-12.13.0-py3-none-any.whl (266 kB)\n",
      "      266.1/266.1 kB 32.2 MB/s eta 0:00:00\n",
      "Collecting pyjwt<3.0.0\n",
      "  Downloading PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
      "Collecting tqdm<5.0.0\n",
      "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "      77.1/77.1 kB 4.6 MB/s eta 0:00:00\n",
      "Collecting azure-mgmt-core<2.0.0,>=1.3.0\n",
      "  Downloading azure_mgmt_core-1.4.0-py3-none-any.whl (27 kB)\n",
      "Collecting strictyaml<2.0.0\n",
      "  Downloading strictyaml-1.7.3-py3-none-any.whl (123 kB)\n",
      "      123.9/123.9 kB 30.1 MB/s eta 0:00:00\n",
      "Collecting jsonschema<5.0.0,>=4.0.0\n",
      "  Downloading jsonschema-4.18.4-py3-none-any.whl (80 kB)\n",
      "      81.0/81.0 kB 12.1 MB/s eta 0:00:00\n",
      "Collecting marshmallow<4.0.0,>=3.5\n",
      "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
      "      49.4/49.4 kB 11.5 MB/s eta 0:00:00\n",
      "Collecting opencensus-ext-azure<2.0.0\n",
      "  Downloading opencensus_ext_azure-1.1.9-py2.py3-none-any.whl (43 kB)\n",
      "      43.0/43.0 kB 7.7 MB/s eta 0:00:00\n",
      "Collecting pyyaml<7.0.0,>=5.1.0\n",
      "  Downloading PyYAML-6.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (736 kB)\n",
      "      736.6/736.6 kB 67.6 MB/s eta 0:00:00\n",
      "Collecting azure-core<2.0.0,>=1.23.0\n",
      "  Downloading azure_core-1.28.0-py3-none-any.whl (185 kB)\n",
      "      185.4/185.4 kB 35.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /azureml-envs/azureml_25db23ddda1880ffc26d032761a7488f/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow->-r /azureml-environment-setup/condaenv.nfmbwtn4.requirements.txt (line 4)) (0.37.1)\n",
      "Collecting requests>=2.18.4\n",
      "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "      62.6/62.6 kB 9.6 MB/s eta 0:00:00\n",
      "Collecting cryptography>=2.1.4\n",
      "  Downloading cryptography-41.0.3-cp37-abi3-manylinux_2_28_x86_64.whl (4.3 MB)\n",
      "      4.3/4.3 MB 110.2 MB/s eta 0:00:00\n",
      "Collecting azure-graphrbac<1.0.0,>=0.40.0\n",
      "  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\n",
      "      141.4/141.4 kB 36.8 MB/s eta 0:00:00\n",
      "Collecting msal<2.0.0,>=1.15.0\n",
      "  Downloading msal-1.23.0-py2.py3-none-any.whl (90 kB)\n",
      "      90.8/90.8 kB 19.8 MB/s eta 0:00:00\n",
      "Collecting knack~=0.10.0\n",
      "  Downloading knack-0.10.1-py3-none-any.whl (61 kB)\n",
      "      61.1/61.1 kB 13.2 MB/s eta 0:00:00\n",
      "Collecting msrestazure<=0.6.4,>=0.4.33\n",
      "  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\n",
      "      40.5/40.5 kB 5.8 MB/s eta 0:00:00\n",
      "Collecting SecretStorage<4.0.0\n",
      "  Downloading SecretStorage-3.3.3-py3-none-any.whl (15 kB)\n",
      "Collecting ndg-httpsclient<=0.5.1\n",
      "  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
      "Collecting azure-mgmt-keyvault<11.0.0,>=0.40.0\n",
      "  Downloading azure_mgmt_keyvault-10.2.3-py3-none-any.whl (811 kB)\n",
      "      811.1/811.1 kB 53.2 MB/s eta 0:00:00\n",
      "Collecting paramiko<4.0.0,>=2.0.8\n",
      "  Downloading paramiko-3.3.1-py3-none-any.whl (224 kB)\n",
      "      224.8/224.8 kB 40.3 MB/s eta 0:00:00\n",
      "Collecting pkginfo\n",
      "  Downloading pkginfo-1.9.6-py3-none-any.whl (30 kB)\n",
      "Collecting msal-extensions<=1.0.0,>=0.3.0\n",
      "  Downloading msal_extensions-1.0.0-py2.py3-none-any.whl (19 kB)\n",
      "Collecting jmespath<2.0.0\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting pytz\n",
      "  Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
      "      502.3/502.3 kB 73.4 MB/s eta 0:00:00\n",
      "Collecting urllib3<2.0.0,>=1.23\n",
      "  Downloading urllib3-1.26.16-py2.py3-none-any.whl (143 kB)\n",
      "      143.1/143.1 kB 26.5 MB/s eta 0:00:00\n",
      "Collecting humanfriendly<11.0,>=4.7\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "      86.8/86.8 kB 11.3 MB/s eta 0:00:00\n",
      "Collecting pathspec<1.0.0\n",
      "  Downloading pathspec-0.11.2-py3-none-any.whl (29 kB)\n",
      "Collecting backports.tempfile\n",
      "  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Collecting pyopenssl<24.0.0\n",
      "  Downloading pyOpenSSL-23.2.0-py3-none-any.whl (59 kB)\n",
      "      59.0/59.0 kB 6.3 MB/s eta 0:00:00\n",
      "Collecting adal<=1.2.7,>=1.2.0\n",
      "  Downloading adal-1.2.7-py2.py3-none-any.whl (55 kB)\n",
      "      55.5/55.5 kB 11.6 MB/s eta 0:00:00\n",
      "Collecting jsonpickle<4.0.0\n",
      "  Downloading jsonpickle-3.0.1-py2.py3-none-any.whl (40 kB)\n",
      "      40.5/40.5 kB 8.2 MB/s eta 0:00:00\n",
      "Collecting contextlib2<22.0.0\n",
      "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting azure-mgmt-resource<=22.0.0,>=15.0.0\n",
      "  Downloading azure_mgmt_resource-22.0.0-py3-none-any.whl (2.4 MB)\n",
      "      2.4/2.4 MB 105.2 MB/s eta 0:00:00\n",
      "Collecting python-dateutil<3.0.0,>=2.7.3\n",
      "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "      247.7/247.7 kB 48.0 MB/s eta 0:00:00\n",
      "Collecting packaging\n",
      "  Downloading packaging-23.0-py3-none-any.whl (42 kB)\n",
      "      42.7/42.7 kB 7.9 MB/s eta 0:00:00\n",
      "Collecting argcomplete<3\n",
      "  Downloading argcomplete-2.1.2-py3-none-any.whl (37 kB)\n",
      "Collecting azure-mgmt-storage<=21.0.0,>=16.0.0\n",
      "  Downloading azure_mgmt_storage-21.0.0-py3-none-any.whl (2.8 MB)\n",
      "      2.8/2.8 MB 105.2 MB/s eta 0:00:00\n",
      "Collecting azure-mgmt-containerregistry<11,>=8.2.0\n",
      "  Downloading azure_mgmt_containerregistry-10.1.0-py3-none-any.whl (1.7 MB)\n",
      "      1.7/1.7 MB 95.1 MB/s eta 0:00:00\n",
      "Collecting docker<7.0.0\n",
      "  Downloading docker-6.1.3-py3-none-any.whl (148 kB)\n",
      "      148.1/148.1 kB 37.5 MB/s eta 0:00:00\n",
      "Collecting azure-mgmt-authorization<4,>=0.40.0\n",
      "  Downloading azure_mgmt_authorization-3.0.0-py3-none-any.whl (965 kB)\n",
      "      965.9/965.9 kB 80.7 MB/s eta 0:00:00\n",
      "Collecting pyarrow<=11.0.0,>=0.17.0\n",
      "  Downloading pyarrow-11.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.0 MB)\n",
      "      35.0/35.0 MB 69.9 MB/s eta 0:00:00\n",
      "Collecting azureml-dataprep<4.12.0a,>=4.11.3a\n",
      "  Downloading azureml_dataprep-4.11.6-py3-none-any.whl (38.2 MB)\n",
      "      38.2/38.2 MB 61.7 MB/s eta 0:00:00\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.23.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "      17.1/17.1 MB 85.2 MB/s eta 0:00:00\n",
      "Collecting fusepy<4.0.0,>=3.0.1\n",
      "  Downloading fusepy-3.0.1.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting flask-cors~=3.0.1\n",
      "  Downloading Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\n",
      "Collecting inference-schema~=1.5.0\n",
      "  Downloading inference_schema-1.5.1-py3-none-any.whl (21 kB)\n",
      "Collecting flask<2.3.0\n",
      "  Downloading Flask-2.2.5-py3-none-any.whl (101 kB)\n",
      "      101.8/101.8 kB 13.9 MB/s eta 0:00:00\n",
      "Collecting gunicorn==20.1.0\n",
      "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
      "      79.5/79.5 kB 3.7 MB/s eta 0:00:00\n",
      "Collecting pydantic<1.11,>=1.9\n",
      "  Downloading pydantic-1.10.12-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "      3.2/3.2 MB 91.3 MB/s eta 0:00:00\n",
      "Collecting rpds-py>=0.7.1\n",
      "  Downloading rpds_py-0.9.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "      1.2/1.2 MB 92.9 MB/s eta 0:00:00\n",
      "Collecting attrs>=22.2.0\n",
      "  Downloading attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "      61.2/61.2 kB 13.7 MB/s eta 0:00:00\n",
      "Collecting pkgutil-resolve-name>=1.3.10\n",
      "  Downloading pkgutil_resolve_name-1.3.10-py3-none-any.whl (4.7 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6\n",
      "  Downloading jsonschema_specifications-2023.7.1-py3-none-any.whl (17 kB)\n",
      "Collecting importlib-resources>=1.4.0\n",
      "  Downloading importlib_resources-6.0.0-py3-none-any.whl (31 kB)\n",
      "Collecting referencing>=0.28.4\n",
      "  Downloading referencing-0.30.0-py3-none-any.whl (25 kB)\n",
      "Collecting requests-oauthlib>=0.5.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /azureml-envs/azureml_25db23ddda1880ffc26d032761a7488f/lib/python3.8/site-packages (from msrest>=0.6.18->azure-ai-ml->-r /azureml-environment-setup/condaenv.nfmbwtn4.requirements.txt (line 6)) (2022.12.7)\n",
      "Collecting opencensus<1.0.0,>=0.11.2\n",
      "  Downloading opencensus-0.11.2-py2.py3-none-any.whl (128 kB)\n",
      "      128.2/128.2 kB 27.2 MB/s eta 0:00:00\n",
      "Collecting azure-identity<2.0.0,>=1.5.0\n",
      "  Downloading azure_identity-1.13.0-py3-none-any.whl (151 kB)\n",
      "      151.6/151.6 kB 38.4 MB/s eta 0:00:00\n",
      "Collecting psutil>=5.6.3\n",
      "  Downloading psutil-5.9.5-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (282 kB)\n",
      "      282.1/282.1 kB 32.3 MB/s eta 0:00:00\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\n",
      "      181.8/181.8 kB 43.8 MB/s eta 0:00:00\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.3.6-py3-none-any.whl (242 kB)\n",
      "      242.5/242.5 kB 29.9 MB/s eta 0:00:00\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.1-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n",
      "      6.6/6.6 MB 106.9 MB/s eta 0:00:00\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.4-py3-none-any.whl (94 kB)\n",
      "      94.2/94.2 kB 17.5 MB/s eta 0:00:00\n",
      "Collecting azureml-dataprep-native<39.0.0,>=38.0.0\n",
      "  Downloading azureml_dataprep_native-38.0.0-cp38-cp38-manylinux1_x86_64.whl (1.4 MB)\n",
      "      1.4/1.4 MB 69.4 MB/s eta 0:00:00\n",
      "Collecting dotnetcore2<4.0.0,>=3.0.0\n",
      "  Downloading dotnetcore2-3.1.23-py3-none-manylinux1_x86_64.whl (31.1 MB)\n",
      "      31.1/31.1 MB 54.1 MB/s eta 0:00:00\n",
      "Collecting cloudpickle<3.0.0,>=1.1.0\n",
      "  Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Collecting azureml-dataprep-rslex~=2.18.4dev0\n",
      "  Downloading azureml_dataprep_rslex-2.18.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.0 MB)\n",
      "      22.0/22.0 MB 99.9 MB/s eta 0:00:00\n",
      "Collecting cffi>=1.12\n",
      "  Downloading cffi-1.15.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
      "      442.7/442.7 kB 20.1 MB/s eta 0:00:00\n",
      "Collecting websocket-client>=0.32.0\n",
      "  Downloading websocket_client-1.6.1-py3-none-any.whl (56 kB)\n",
      "      56.9/56.9 kB 12.3 MB/s eta 0:00:00\n",
      "Collecting click>=8.0\n",
      "  Downloading click-8.1.6-py3-none-any.whl (97 kB)\n",
      "      97.9/97.9 kB 17.5 MB/s eta 0:00:00\n",
      "Collecting Jinja2>=3.0\n",
      "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "      133.1/133.1 kB 12.9 MB/s eta 0:00:00\n",
      "Collecting itsdangerous>=2.0\n",
      "  Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
      "Collecting importlib-metadata>=3.6.0\n",
      "  Downloading importlib_metadata-6.8.0-py3-none-any.whl (22 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "      181.3/181.3 kB 18.4 MB/s eta 0:00:00\n",
      "Collecting zipp>=3.1.0\n",
      "  Downloading zipp-3.16.2-py3-none-any.whl (7.2 kB)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pygments\n",
      "  Downloading Pygments-2.15.1-py3-none-any.whl (1.1 MB)\n",
      "      1.1/1.1 MB 91.8 MB/s eta 0:00:00\n",
      "Collecting tabulate\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Collecting portalocker<3,>=1.0\n",
      "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting pyasn1>=0.1.1\n",
      "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "      83.9/83.9 kB 17.3 MB/s eta 0:00:00\n",
      "Collecting opencensus-context>=0.1.3\n",
      "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
      "Collecting google-api-core<3.0.0,>=1.0.0\n",
      "  Downloading google_api_core-2.11.1-py3-none-any.whl (120 kB)\n",
      "      120.5/120.5 kB 17.6 MB/s eta 0:00:00\n",
      "Collecting bcrypt>=3.2\n",
      "  Downloading bcrypt-4.0.1-cp36-abi3-manylinux_2_28_x86_64.whl (593 kB)\n",
      "      593.7/593.7 kB 43.8 MB/s eta 0:00:00\n",
      "Collecting pynacl>=1.5\n",
      "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
      "      856.7/856.7 kB 75.2 MB/s eta 0:00:00\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
      "      61.5/61.5 kB 13.8 MB/s eta 0:00:00\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (199 kB)\n",
      "      199.1/199.1 kB 19.9 MB/s eta 0:00:00\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "      151.7/151.7 kB 29.8 MB/s eta 0:00:00\n",
      "Collecting PySocks!=1.5.7,>=1.5.6\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Collecting jeepney>=0.6\n",
      "  Downloading jeepney-0.8.0-py3-none-any.whl (48 kB)\n",
      "      48.4/48.4 kB 8.7 MB/s eta 0:00:00\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Downloading MarkupSafe-2.1.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Collecting backports.weakref\n",
      "  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "      118.7/118.7 kB 25.5 MB/s eta 0:00:00\n",
      "Collecting distro>=1.2.0\n",
      "  Downloading distro-1.8.0-py3-none-any.whl (20 kB)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2\n",
      "  Downloading googleapis_common_protos-1.60.0-py2.py3-none-any.whl (227 kB)\n",
      "      227.6/227.6 kB 41.0 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: fusepy, wrapt\n",
      "  Building wheel for fusepy (setup.py): started\n",
      "  Building wheel for fusepy (setup.py): finished with status 'done'\n",
      "  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10486 sha256=a65f362b8611bd29643c30f825421d28dbe7b4f7acda4f813a40b76fc435c7ec\n",
      "  Stored in directory: /root/.cache/pip/wheels/db/01/ee/105147547cf0ecd1031b26901757e1f17c98902c8cc7bcaa47\n",
      "  Building wheel for wrapt (setup.py): started\n",
      "  Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "  Created wheel for wrapt: filename=wrapt-1.12.1-cp38-cp38-linux_x86_64.whl size=81695 sha256=1b031f884e753d20841f6d57afb6b209ffcef838b76b8b88dfbbdd7b7c79cceb\n",
      "  Stored in directory: /root/.cache/pip/wheels/67/a1/46/13226bbf258069e74ce1598cd4077014852a5e63434be9f1c6\n",
      "Successfully built fusepy wrapt\n",
      "Installing collected packages: wrapt, pytz, opencensus-context, libclang, fusepy, flatbuffers, backports.weakref, azureml-dataprep-rslex, azureml-dataprep-native, azure-common, zipp, websocket-client, urllib3, typing-extensions, tqdm, threadpoolctl, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, tabulate, six, rpds-py, pyyaml, PySocks, pyjwt, pygments, pydash, pycparser, pyasn1, psutil, protobuf, portalocker, pkgutil-resolve-name, pkginfo, Pillow, pathspec, packaging, oauthlib, numpy, MarkupSafe, keras, jsonpickle, joblib, jmespath, jeepney, itsdangerous, idna, humanfriendly, gunicorn, grpcio, gast, distro, contextlib2, colorama, cloudpickle, click, charset-normalizer, cachetools, bcrypt, backports.tempfile, attrs, argcomplete, absl-py, werkzeug, scipy, rsa, requests, referencing, python-dateutil, pydantic, pyasn1-modules, pyarrow, opt-einsum, marshmallow, knack, Jinja2, isodate, importlib-resources, importlib-metadata, h5py, googleapis-common-protos, google-pasta, dotnetcore2, cffi, astunparse, strictyaml, scikit-learn, requests-oauthlib, pynacl, markdown, jsonschema-specifications, inference-schema, google-auth, flask, docker, cryptography, azure-core, SecretStorage, pyopenssl, paramiko, msrest, jsonschema, google-auth-oauthlib, google-api-core, flask-cors, azure-storage-file-share, azure-storage-blob, azure-mgmt-core, adal, tensorboard, opencensus, ndg-httpsclient, msrestazure, msal, azure-storage-file-datalake, azure-mgmt-storage, azure-mgmt-resource, azure-mgmt-keyvault, azure-mgmt-containerregistry, azure-mgmt-authorization, tensorflow, msal-extensions, azure-graphrbac, azureml-core, azure-identity, opencensus-ext-azure, azureml-dataprep, azureml-inference-server-http, azureml-dataset-runtime, azure-ai-ml, azureml-defaults\n",
      "Successfully installed Jinja2-3.1.2 MarkupSafe-2.1.3 Pillow-10.0.0 PySocks-1.7.1 SecretStorage-3.3.3 absl-py-1.4.0 adal-1.2.7 argcomplete-2.1.2 astunparse-1.6.3 attrs-23.1.0 azure-ai-ml-1.9.0 azure-common-1.1.28 azure-core-1.28.0 azure-graphrbac-0.61.1 azure-identity-1.13.0 azure-mgmt-authorization-3.0.0 azure-mgmt-containerregistry-10.1.0 azure-mgmt-core-1.4.0 azure-mgmt-keyvault-10.2.3 azure-mgmt-resource-22.0.0 azure-mgmt-storage-21.0.0 azure-storage-blob-12.17.0 azure-storage-file-datalake-12.12.0 azure-storage-file-share-12.13.0 azureml-core-1.52.0 azureml-dataprep-4.11.6 azureml-dataprep-native-38.0.0 azureml-dataprep-rslex-2.18.5 azureml-dataset-runtime-1.52.0 azureml-defaults-1.52.0 azureml-inference-server-http-0.8.4 backports.tempfile-1.0 backports.weakref-1.0.post1 bcrypt-4.0.1 cachetools-5.3.1 cffi-1.15.1 charset-normalizer-3.2.0 click-8.1.6 cloudpickle-2.2.1 colorama-0.4.6 contextlib2-21.6.0 cryptography-41.0.3 distro-1.8.0 docker-6.1.3 dotnetcore2-3.1.23 flask-2.2.5 flask-cors-3.0.10 flatbuffers-23.5.26 fusepy-3.0.1 gast-0.4.0 google-api-core-2.11.1 google-auth-2.22.0 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 googleapis-common-protos-1.60.0 grpcio-1.56.2 gunicorn-20.1.0 h5py-3.9.0 humanfriendly-10.0 idna-3.4 importlib-metadata-6.8.0 importlib-resources-6.0.0 inference-schema-1.5.1 isodate-0.6.1 itsdangerous-2.1.2 jeepney-0.8.0 jmespath-1.0.1 joblib-1.3.1 jsonpickle-3.0.1 jsonschema-4.18.4 jsonschema-specifications-2023.7.1 keras-2.13.1 knack-0.10.1 libclang-16.0.6 markdown-3.4.4 marshmallow-3.20.1 msal-1.23.0 msal-extensions-1.0.0 msrest-0.7.1 msrestazure-0.6.4 ndg-httpsclient-0.5.1 numpy-1.23.5 oauthlib-3.2.2 opencensus-0.11.2 opencensus-context-0.1.3 opencensus-ext-azure-1.1.9 opt-einsum-3.3.0 packaging-23.0 paramiko-3.3.1 pathspec-0.11.2 pkginfo-1.9.6 pkgutil-resolve-name-1.3.10 portalocker-2.7.0 protobuf-4.23.4 psutil-5.9.5 pyarrow-11.0.0 pyasn1-0.5.0 pyasn1-modules-0.3.0 pycparser-2.21 pydantic-1.10.12 pydash-5.1.2 pygments-2.15.1 pyjwt-2.8.0 pynacl-1.5.0 pyopenssl-23.2.0 python-dateutil-2.8.2 pytz-2023.3 pyyaml-6.0.1 referencing-0.30.0 requests-2.31.0 requests-oauthlib-1.3.1 rpds-py-0.9.2 rsa-4.9 scikit-learn-1.3.0 scipy-1.10.1 six-1.16.0 strictyaml-1.7.3 tabulate-0.9.0 tensorboard-2.13.0 tensorboard-data-server-0.7.1 tensorflow-2.13.0 tensorflow-estimator-2.13.0 tensorflow-io-gcs-filesystem-0.33.0 termcolor-2.3.0 threadpoolctl-3.2.0 tqdm-4.65.0 typing-extensions-4.5.0 urllib3-1.26.16 websocket-client-1.6.1 werkzeug-2.3.6 wrapt-1.12.1 zipp-3.16.2\n",
      "\n",
      "done\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate /azureml-envs/azureml_25db23ddda1880ffc26d032761a7488f\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n",
      "Removing intermediate container cec2a905dbaa\n",
      " ---> fc4f4e0d8010\n",
      "Step 9/21 : ENV PATH /azureml-envs/azureml_25db23ddda1880ffc26d032761a7488f/bin:$PATH\n",
      " ---> Running in 16fa1398624e\n",
      "Removing intermediate container 16fa1398624e\n",
      " ---> c41ccbf14095\n",
      "Step 10/21 : COPY azureml-environment-setup/send_conda_dependencies.py azureml-environment-setup/send_conda_dependencies.py\n",
      " ---> 219d0ef1696c\n",
      "Step 11/21 : RUN echo \"Copying environment context\"\n",
      " ---> Running in 637fccae74ae\n",
      "Copying environment context\n",
      "Removing intermediate container 637fccae74ae\n",
      " ---> c149c7b28fff\n",
      "Step 12/21 : COPY azureml-environment-setup/environment_context.json azureml-environment-setup/environment_context.json\n",
      " ---> 4162c712749a\n",
      "Step 13/21 : RUN python /azureml-environment-setup/send_conda_dependencies.py -p /azureml-envs/azureml_25db23ddda1880ffc26d032761a7488f\n",
      " ---> Running in 3cb1e6489dc8\n",
      "Report materialized dependencies for the environment\n",
      "Reading environment context\n",
      "Exporting conda environment\n",
      "Sending request with materialized conda environment details\n",
      "Successfully sent materialized environment details\n",
      "Removing intermediate container 3cb1e6489dc8\n",
      " ---> 823241ac5f23\n",
      "Step 14/21 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_25db23ddda1880ffc26d032761a7488f\n",
      " ---> Running in af01709d419b\n",
      "Removing intermediate container af01709d419b\n",
      " ---> e8c414644146\n",
      "Step 15/21 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_25db23ddda1880ffc26d032761a7488f/lib:$LD_LIBRARY_PATH\n",
      " ---> Running in c773f7ccde17\n",
      "Removing intermediate container c773f7ccde17\n",
      " ---> 131375d59743\n",
      "Step 16/21 : ENV CONDA_DEFAULT_ENV=azureml_25db23ddda1880ffc26d032761a7488f CONDA_PREFIX=/azureml-envs/azureml_25db23ddda1880ffc26d032761a7488f\n",
      " ---> Running in 5ba44502d28e\n",
      "Removing intermediate container 5ba44502d28e\n",
      " ---> f1d0c8926ce4\n",
      "Step 17/21 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n",
      " ---> d4e18b3183ec\n",
      "Step 18/21 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit  /azureml-environment-setup/spark_cache.py'; fi\n",
      " ---> Running in b48738f49ed6\n",
      "Removing intermediate container b48738f49ed6\n",
      " ---> 938f86436f68\n",
      "Step 19/21 : RUN rm -rf azureml-environment-setup\n",
      " ---> Running in b6fb5ca640c0\n",
      "Removing intermediate container b6fb5ca640c0\n",
      " ---> eb47f81859a9\n",
      "Step 20/21 : ENV AZUREML_ENVIRONMENT_IMAGE True\n",
      " ---> Running in bf236a697839\n",
      "Removing intermediate container bf236a697839\n",
      " ---> 136d798e793e\n",
      "Step 21/21 : CMD [\"bash\"]\n",
      " ---> Running in b176eb19bfbf\n",
      "Removing intermediate container b176eb19bfbf\n",
      " ---> f1545d63925b\n",
      "Successfully built f1545d63925b\n",
      "Successfully tagged 19fdcc1f9a94406985698a8d8e694586.azurecr.io/azureml/azureml_d8f5784967ae28d8d3972aa82dacbc7a:latest\n",
      "Successfully tagged 19fdcc1f9a94406985698a8d8e694586.azurecr.io/azureml/azureml_d8f5784967ae28d8d3972aa82dacbc7a:1\n",
      "2023/08/02 05:02:06 Successfully executed container: acb_step_0\n",
      "2023/08/02 05:02:06 Executing step ID: acb_step_1. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2023/08/02 05:02:06 Pushing image: 19fdcc1f9a94406985698a8d8e694586.azurecr.io/azureml/azureml_d8f5784967ae28d8d3972aa82dacbc7a:1, attempt 1\n",
      "The push refers to repository [19fdcc1f9a94406985698a8d8e694586.azurecr.io/azureml/azureml_d8f5784967ae28d8d3972aa82dacbc7a]\n",
      "1d1d27bc918a: Preparing\n",
      "bfab5e2459b3: Preparing\n",
      "0c82b8fd80ef: Preparing\n",
      "f6b235eb661a: Preparing\n",
      "8ae9edb1ba0e: Preparing\n",
      "02c888a6ce5a: Preparing\n",
      "421de19f686e: Preparing\n",
      "990c6cca36bf: Preparing\n",
      "34f8f6054b75: Preparing\n",
      "c5a975574b38: Preparing\n",
      "4c69ce4f44f6: Preparing\n",
      "bcc112b4116c: Preparing\n",
      "99ef6c683a24: Preparing\n",
      "18b098ded0ea: Preparing\n",
      "3fc1c0b62fcf: Preparing\n",
      "f286d67d4dc0: Preparing\n",
      "61450ca0c200: Preparing\n",
      "c00a48d0d0a5: Preparing\n",
      "ec66d8cea54a: Preparing\n",
      "02c888a6ce5a: Waiting\n",
      "421de19f686e: Waiting\n",
      "990c6cca36bf: Waiting\n",
      "34f8f6054b75: Waiting\n",
      "c5a975574b38: Waiting\n",
      "4c69ce4f44f6: Waiting\n",
      "bcc112b4116c: Waiting\n",
      "99ef6c683a24: Waiting\n",
      "18b098ded0ea: Waiting\n",
      "f286d67d4dc0: Waiting\n",
      "61450ca0c200: Waiting\n",
      "c00a48d0d0a5: Waiting\n",
      "3fc1c0b62fcf: Waiting\n",
      "ec66d8cea54a: Waiting\n",
      "8ae9edb1ba0e: Pushed\n",
      "1d1d27bc918a: Pushed\n",
      "bfab5e2459b3: Pushed\n",
      "f6b235eb661a: Pushed\n",
      "421de19f686e: Pushed\n",
      "0c82b8fd80ef: Pushed\n",
      "34f8f6054b75: Pushed\n",
      "990c6cca36bf: Pushed\n",
      "c5a975574b38: Pushed\n",
      "4c69ce4f44f6: Pushed\n",
      "3fc1c0b62fcf: Pushed\n",
      "bcc112b4116c: Pushed\n",
      "99ef6c683a24: Pushed\n",
      "61450ca0c200: Pushed\n",
      "f286d67d4dc0: Pushed\n",
      "ec66d8cea54a: Pushed\n",
      "18b098ded0ea: Pushed\n",
      "c00a48d0d0a5: Pushed\n",
      "02c888a6ce5a: Pushed\n",
      "1: digest: sha256:ae510acd11ef09d978fae8afe09c8cf9f3db44faf19c9f00e250494ae223138d size: 4305\n",
      "2023/08/02 05:04:13 Successfully pushed image: 19fdcc1f9a94406985698a8d8e694586.azurecr.io/azureml/azureml_d8f5784967ae28d8d3972aa82dacbc7a:1\n",
      "2023/08/02 05:04:13 Executing step ID: acb_step_2. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2023/08/02 05:04:13 Pushing image: 19fdcc1f9a94406985698a8d8e694586.azurecr.io/azureml/azureml_d8f5784967ae28d8d3972aa82dacbc7a:latest, attempt 1\n",
      "The push refers to repository [19fdcc1f9a94406985698a8d8e694586.azurecr.io/azureml/azureml_d8f5784967ae28d8d3972aa82dacbc7a]\n",
      "1d1d27bc918a: Preparing\n",
      "bfab5e2459b3: Preparing\n",
      "0c82b8fd80ef: Preparing\n",
      "f6b235eb661a: Preparing\n",
      "8ae9edb1ba0e: Preparing\n",
      "02c888a6ce5a: Preparing\n",
      "421de19f686e: Preparing\n",
      "990c6cca36bf: Preparing\n",
      "34f8f6054b75: Preparing\n",
      "c5a975574b38: Preparing\n",
      "4c69ce4f44f6: Preparing\n",
      "bcc112b4116c: Preparing\n",
      "99ef6c683a24: Preparing\n",
      "18b098ded0ea: Preparing\n",
      "3fc1c0b62fcf: Preparing\n",
      "f286d67d4dc0: Preparing\n",
      "61450ca0c200: Preparing\n",
      "c00a48d0d0a5: Preparing\n",
      "ec66d8cea54a: Preparing\n",
      "02c888a6ce5a: Waiting\n",
      "421de19f686e: Waiting\n",
      "990c6cca36bf: Waiting\n",
      "34f8f6054b75: Waiting\n",
      "c5a975574b38: Waiting\n",
      "4c69ce4f44f6: Waiting\n",
      "bcc112b4116c: Waiting\n",
      "99ef6c683a24: Waiting\n",
      "18b098ded0ea: Waiting\n",
      "3fc1c0b62fcf: Waiting\n",
      "f286d67d4dc0: Waiting\n",
      "61450ca0c200: Waiting\n",
      "c00a48d0d0a5: Waiting\n",
      "ec66d8cea54a: Waiting\n",
      "f6b235eb661a: Layer already exists\n",
      "1d1d27bc918a: Layer already exists\n",
      "0c82b8fd80ef: Layer already exists\n",
      "bfab5e2459b3: Layer already exists\n",
      "8ae9edb1ba0e: Layer already exists\n",
      "02c888a6ce5a: Layer already exists\n",
      "990c6cca36bf: Layer already exists\n",
      "421de19f686e: Layer already exists\n",
      "4c69ce4f44f6: Layer already exists\n",
      "c5a975574b38: Layer already exists\n",
      "99ef6c683a24: Layer already exists\n",
      "34f8f6054b75: Layer already exists\n",
      "bcc112b4116c: Layer already exists\n",
      "18b098ded0ea: Layer already exists\n",
      "61450ca0c200: Layer already exists\n",
      "f286d67d4dc0: Layer already exists\n",
      "c00a48d0d0a5: Layer already exists\n",
      "3fc1c0b62fcf: Layer already exists\n",
      "ec66d8cea54a: Layer already exists\n",
      "latest: digest: sha256:ae510acd11ef09d978fae8afe09c8cf9f3db44faf19c9f00e250494ae223138d size: 4305\n",
      "2023/08/02 05:04:19 Successfully pushed image: 19fdcc1f9a94406985698a8d8e694586.azurecr.io/azureml/azureml_d8f5784967ae28d8d3972aa82dacbc7a:latest\n",
      "2023/08/02 05:04:19 Executing step ID: acb_step_3. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2023/08/02 05:04:19 Launching container with name: acb_step_3\n",
      "Report materialized dependencies for the environment\n",
      "Reading environment context\n",
      "Exporting conda environment\n",
      "Sending request with materialized conda environment details\n",
      "Successfully sent materialized environment dependencies\n",
      "2023/08/02 05:04:23 Successfully executed container: acb_step_3\n",
      "2023/08/02 05:04:23 Step ID: acb_step_0 marked as successful (elapsed time in seconds: 310.280503)\n",
      "2023/08/02 05:04:23 Populating digests for step ID: acb_step_0...\n",
      "2023/08/02 05:04:25 Successfully populated digests for step ID: acb_step_0\n",
      "2023/08/02 05:04:25 Step ID: acb_step_1 marked as successful (elapsed time in seconds: 126.684024)\n",
      "2023/08/02 05:04:25 Step ID: acb_step_2 marked as successful (elapsed time in seconds: 6.308444)\n",
      "2023/08/02 05:04:25 Step ID: acb_step_3 marked as successful (elapsed time in seconds: 4.302635)\n",
      "2023/08/02 05:04:25 The following dependencies were found:\n",
      "2023/08/02 05:04:25 \n",
      "- image:\n",
      "    registry: 19fdcc1f9a94406985698a8d8e694586.azurecr.io\n",
      "    repository: azureml/azureml_d8f5784967ae28d8d3972aa82dacbc7a\n",
      "    tag: latest\n",
      "    digest: sha256:ae510acd11ef09d978fae8afe09c8cf9f3db44faf19c9f00e250494ae223138d\n",
      "  runtime-dependency:\n",
      "    registry: mcr.microsoft.com\n",
      "    repository: azureml/openmpi4.1.0-ubuntu20.04\n",
      "    tag: 20230620.v1\n",
      "    digest: sha256:d87e60a40761fd1bb9efa97d94a9ec52b62a9e7081fd2acd5c7d94ba2852d60a\n",
      "  git: {}\n",
      "- image:\n",
      "    registry: 19fdcc1f9a94406985698a8d8e694586.azurecr.io\n",
      "    repository: azureml/azureml_d8f5784967ae28d8d3972aa82dacbc7a\n",
      "    tag: \"1\"\n",
      "    digest: sha256:ae510acd11ef09d978fae8afe09c8cf9f3db44faf19c9f00e250494ae223138d\n",
      "  runtime-dependency:\n",
      "    registry: mcr.microsoft.com\n",
      "    repository: azureml/openmpi4.1.0-ubuntu20.04\n",
      "    tag: 20230620.v1\n",
      "    digest: sha256:d87e60a40761fd1bb9efa97d94a9ec52b62a9e7081fd2acd5c7d94ba2852d60a\n",
      "  git: {}\n",
      "\n",
      "\n",
      "Run ID: ca2 was successful after 7m33s\n",
      "\n",
      "Streaming user_logs/std_log.txt\n",
      "===============================\n",
      "\n",
      "Cleaning up all outstanding Run operations, waiting 300.0 seconds\n",
      "0 items cleaning up...\n",
      "Cleanup took 1.1920928955078125e-06 seconds\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 197, in <module>\n",
      "  File \"<string>\", line 193, in main\n",
      "  File \"/azureml-envs/azureml_25db23ddda1880ffc26d032761a7488f/lib/python3.8/runpy.py\", line 264, in run_path\n",
      "    code, fname = _get_code_from_file(run_name, path_name)\n",
      "  File \"/azureml-envs/azureml_25db23ddda1880ffc26d032761a7488f/lib/python3.8/runpy.py\", line 239, in _get_code_from_file\n",
      "    code = compile(f.read(), fname, 'exec')\n",
      "  File \"Ground_Based_Training_script.py\", line 4\n",
      "    import scikit-learn\n",
      "                 ^\n",
      "SyntaxError: invalid syntax\n",
      "\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: contrail_classifier_1690952204_c78a77a3\n",
      "Web View: https://ml.azure.com/runs/contrail_classifier_1690952204_c78a77a3?wsid=/subscriptions/81ccb9cf-adc5-4eac-b781-5b1fc76926f7/resourcegroups/ContrailResourceGroup/workspaces/Contrail-Classifier&tid=85b77843-1ccd-4a9b-9b12-baa93c8b4d37\n",
      "\n",
      "Warnings:\n",
      "AzureMLCompute job failed\n",
      "ExecutionFailed: [REDACTED]\n",
      "\texit_codes: 1\n",
      "\tAppinsights Reachable: Some(true)\n",
      "\n"
     ]
    },
    {
     "ename": "ActivityFailedException",
     "evalue": "ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Execution failed. User process '/azureml-envs/azureml_25db23ddda1880ffc26d032761a7488f/bin/python' exited with status code 1. Please check log file 'user_logs/std_log.txt' for error details. Error: Traceback (most recent call last):\\n  File \\\"<string>\\\", line 197, in <module>\\n  File \\\"<string>\\\", line 193, in main\\n  File \\\"/azureml-envs/azureml_25db23ddda1880ffc26d032761a7488f/lib/python3.8/runpy.py\\\", line 264, in run_path\\n    code, fname = _get_code_from_file(run_name, path_name)\\n  File \\\"/azureml-envs/azureml_25db23ddda1880ffc26d032761a7488f/lib/python3.8/runpy.py\\\", line 239, in _get_code_from_file\\n    code = compile(f.read(), fname, 'exec')\\n  File \\\"Ground_Based_Training_script.py\\\", line 4\\n    import scikit-learn\\n                 ^\\nSyntaxError: invalid syntax\\n\\n\",\n        \"messageParameters\": {},\n        \"details\": []\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\",\n    \"componentName\": \"CommonRuntime\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"Execution failed. User process '/azureml-envs/azureml_25db23ddda1880ffc26d032761a7488f/bin/python' exited with status code 1. Please check log file 'user_logs/std_log.txt' for error details. Error: Traceback (most recent call last):\\\\n  File \\\\\\\"<string>\\\\\\\", line 197, in <module>\\\\n  File \\\\\\\"<string>\\\\\\\", line 193, in main\\\\n  File \\\\\\\"/azureml-envs/azureml_25db23ddda1880ffc26d032761a7488f/lib/python3.8/runpy.py\\\\\\\", line 264, in run_path\\\\n    code, fname = _get_code_from_file(run_name, path_name)\\\\n  File \\\\\\\"/azureml-envs/azureml_25db23ddda1880ffc26d032761a7488f/lib/python3.8/runpy.py\\\\\\\", line 239, in _get_code_from_file\\\\n    code = compile(f.read(), fname, 'exec')\\\\n  File \\\\\\\"Ground_Based_Training_script.py\\\\\\\", line 4\\\\n    import scikit-learn\\\\n                 ^\\\\nSyntaxError: invalid syntax\\\\n\\\\n\\\",\\n        \\\"messageParameters\\\": {},\\n        \\\"details\\\": []\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\",\\n    \\\"componentName\\\": \\\"CommonRuntime\\\"\\n}\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mActivityFailedException\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39m# Submit the experiment\u001b[39;00m\n\u001b[0;32m      6\u001b[0m run \u001b[39m=\u001b[39m experiment\u001b[39m.\u001b[39msubmit(config\u001b[39m=\u001b[39msrc)\n\u001b[1;32m----> 7\u001b[0m run\u001b[39m.\u001b[39;49mwait_for_completion(show_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\sebas\\anaconda3\\Lib\\site-packages\\azureml\\core\\run.py:849\u001b[0m, in \u001b[0;36mRun.wait_for_completion\u001b[1;34m(self, show_output, wait_post_processing, raise_on_error)\u001b[0m\n\u001b[0;32m    847\u001b[0m \u001b[39mif\u001b[39;00m show_output:\n\u001b[0;32m    848\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 849\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stream_run_output(\n\u001b[0;32m    850\u001b[0m             file_handle\u001b[39m=\u001b[39;49msys\u001b[39m.\u001b[39;49mstdout,\n\u001b[0;32m    851\u001b[0m             wait_post_processing\u001b[39m=\u001b[39;49mwait_post_processing,\n\u001b[0;32m    852\u001b[0m             raise_on_error\u001b[39m=\u001b[39;49mraise_on_error)\n\u001b[0;32m    853\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_details()\n\u001b[0;32m    854\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\sebas\\anaconda3\\Lib\\site-packages\\azureml\\core\\run.py:1102\u001b[0m, in \u001b[0;36mRun._stream_run_output\u001b[1;34m(self, file_handle, wait_post_processing, raise_on_error)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         file_handle\u001b[39m.\u001b[39mwrite(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1101\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1102\u001b[0m         \u001b[39mraise\u001b[39;00m ActivityFailedException(error_details\u001b[39m=\u001b[39mjson\u001b[39m.\u001b[39mdumps(error, indent\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m))\n\u001b[0;32m   1104\u001b[0m file_handle\u001b[39m.\u001b[39mwrite(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1105\u001b[0m file_handle\u001b[39m.\u001b[39mflush()\n",
      "\u001b[1;31mActivityFailedException\u001b[0m: ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Execution failed. User process '/azureml-envs/azureml_25db23ddda1880ffc26d032761a7488f/bin/python' exited with status code 1. Please check log file 'user_logs/std_log.txt' for error details. Error: Traceback (most recent call last):\\n  File \\\"<string>\\\", line 197, in <module>\\n  File \\\"<string>\\\", line 193, in main\\n  File \\\"/azureml-envs/azureml_25db23ddda1880ffc26d032761a7488f/lib/python3.8/runpy.py\\\", line 264, in run_path\\n    code, fname = _get_code_from_file(run_name, path_name)\\n  File \\\"/azureml-envs/azureml_25db23ddda1880ffc26d032761a7488f/lib/python3.8/runpy.py\\\", line 239, in _get_code_from_file\\n    code = compile(f.read(), fname, 'exec')\\n  File \\\"Ground_Based_Training_script.py\\\", line 4\\n    import scikit-learn\\n                 ^\\nSyntaxError: invalid syntax\\n\\n\",\n        \"messageParameters\": {},\n        \"details\": []\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\",\n    \"componentName\": \"CommonRuntime\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"Execution failed. User process '/azureml-envs/azureml_25db23ddda1880ffc26d032761a7488f/bin/python' exited with status code 1. Please check log file 'user_logs/std_log.txt' for error details. Error: Traceback (most recent call last):\\\\n  File \\\\\\\"<string>\\\\\\\", line 197, in <module>\\\\n  File \\\\\\\"<string>\\\\\\\", line 193, in main\\\\n  File \\\\\\\"/azureml-envs/azureml_25db23ddda1880ffc26d032761a7488f/lib/python3.8/runpy.py\\\\\\\", line 264, in run_path\\\\n    code, fname = _get_code_from_file(run_name, path_name)\\\\n  File \\\\\\\"/azureml-envs/azureml_25db23ddda1880ffc26d032761a7488f/lib/python3.8/runpy.py\\\\\\\", line 239, in _get_code_from_file\\\\n    code = compile(f.read(), fname, 'exec')\\\\n  File \\\\\\\"Ground_Based_Training_script.py\\\\\\\", line 4\\\\n    import scikit-learn\\\\n                 ^\\\\nSyntaxError: invalid syntax\\\\n\\\\n\\\",\\n        \\\"messageParameters\\\": {},\\n        \\\"details\\\": []\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\",\\n    \\\"componentName\\\": \\\"CommonRuntime\\\"\\n}\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "# Create an experiment\n",
    "experiment_name = 'contrail_classifier'\n",
    "experiment = Experiment(workspace=ws, name=experiment_name)\n",
    "\n",
    "# Submit the experiment\n",
    "run = experiment.submit(config=src)\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Model\n",
    "When dealing with imbalanced classes, traditional metrics like accuracy can be misleading. For a task where avoiding false positives (i.e., the model predicting a positive class when it's actually negative) is important, you might want to consider the following metrics:\n",
    "\n",
    "* Precision: Precision is the ratio of true positives (TP) to the sum of true positives and false positives (FP). Precision is directly concerned with minimizing false positive predictions. Precision = TP / (TP + FP)\n",
    "\n",
    "* F1 Score: The F1 score is the harmonic mean of precision and recall. While it doesn't directly focus on false positives, it provides a balance between precision and recall. This can be useful if both false positives and false negatives are of concern.\n",
    "\n",
    "* Area Under the Precision-Recall Curve (AUPRC): In an imbalanced classification problem, AUPRC can be a better metric than traditional ones. It calculates the area under the curve formed by plotting recall (x-axis) against precision (y-axis) at various threshold settings. The closer this area is to 1, the better the model is at distinguishing between the positive and negative classes.\n",
    "\n",
    "For the cost function in the training phase of a neural network, the standard is cross-entropy loss. When dealing with imbalanced classes, one way to handle this is by applying class weights to the loss function, which assigns a higher penalty for misclassifying the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test_tensor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
